{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c882ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain_suicide_captum_all.py\n",
    "# Single sample and batch explainability for the suicidal class\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from captum.attr import LayerIntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63ba0f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x215a3a9c9d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# Path helpers and config\n",
    "# =========================\n",
    "\n",
    "def find_data_warehouse(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        dw = p / \"Data_Warehouse\"\n",
    "        if dw.exists():\n",
    "            return dw\n",
    "    raise FileNotFoundError(\"Could not locate a folder named Data_Warehouse. Set DATA_WAREHOUSE manually.\")\n",
    "\n",
    "\n",
    "try:\n",
    "    SCRIPT_DIR = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    SCRIPT_DIR = Path.cwd()\n",
    "\n",
    "DATA_WAREHOUSE = find_data_warehouse(SCRIPT_DIR)\n",
    "SPLIT_DIR = DATA_WAREHOUSE / \"mental_health_splits_no_stress\"\n",
    "MODEL_BASE = SPLIT_DIR / \"all_roberta_large_v1_multiclass\"\n",
    "BEST_DIR = MODEL_BASE / \"best\"\n",
    "OUTPUT_DIR = MODEL_BASE / \"XAI\"\n",
    "MODEL_DIR = BEST_DIR if BEST_DIR.exists() else MODEL_BASE\n",
    "\n",
    "MAX_LEN = 384\n",
    "N_STEPS_IG = 30\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65bf8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Data and label mapping\n",
    "# =========================\n",
    "\n",
    "def load_test_and_mapping():\n",
    "    test_path = SPLIT_DIR / \"test.csv\"\n",
    "    if not test_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing test.csv at {test_path}\")\n",
    "    df_test = pd.read_csv(test_path)\n",
    "\n",
    "    label_map_path = SPLIT_DIR / \"label_classes.csv\"\n",
    "    if label_map_path.exists():\n",
    "        df_map = pd.read_csv(label_map_path, header=None)\n",
    "        if df_map.shape[1] == 2:\n",
    "            class_to_id = {str(df_map.iloc[i, 0]).strip().lower(): int(df_map.iloc[i, 1]) for i in range(len(df_map))}\n",
    "        else:\n",
    "            class_to_id = {str(df_map.iloc[i, -2]).strip().lower(): int(df_map.iloc[i, -1]) for i in range(len(df_map))}\n",
    "    else:\n",
    "        uniq = sorted([lbl for lbl in df_test[\"label\"].astype(str).str.lower().unique() if lbl != \"none\"])\n",
    "        class_to_id = {lbl: i for i, lbl in enumerate(uniq)}\n",
    "        class_to_id[\"none\"] = 4\n",
    "\n",
    "    id_to_class = {v: k for k, v in class_to_id.items()}\n",
    "    if \"suicide\" not in class_to_id:\n",
    "        raise ValueError(f\"Label mapping does not contain 'suicidal'. Found {list(class_to_id.keys())}\")\n",
    "\n",
    "    return df_test, class_to_id, id_to_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2ee860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Model and tokenizer\n",
    "# =========================\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    tok = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=True)\n",
    "    mdl = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "    mdl.to(DEVICE)\n",
    "    mdl.eval()\n",
    "    return tok, mdl\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Core utilities\n",
    "# =========================\n",
    "\n",
    "def forward_fn(model, input_ids: torch.Tensor, attention_mask: torch.Tensor):\n",
    "    return model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "\n",
    "def encode_one(tokenizer, text: str):\n",
    "    enc = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=False,\n",
    "        add_special_tokens=True,\n",
    "    )\n",
    "    return {k: v.to(DEVICE) for k, v in enc.items()}\n",
    "\n",
    "def build_baseline_like(tokenizer, input_ids: torch.Tensor):\n",
    "    pad_id = tokenizer.pad_token_id or tokenizer.eos_token_id or 1\n",
    "    return torch.full_like(input_ids, fill_value=pad_id)\n",
    "\n",
    "def tokens_from_ids(tokenizer, ids: torch.Tensor):\n",
    "    return tokenizer.convert_ids_to_tokens(ids.detach().cpu().tolist())\n",
    "\n",
    "def merge_roberta_pieces(tokenizer, tokens, scores, drop_special=True):\n",
    "    special_set = {\n",
    "        tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token,\n",
    "        tokenizer.eos_token, tokenizer.bos_token\n",
    "    }\n",
    "    words = []\n",
    "    word_scores = []\n",
    "    cur_word = \"\"\n",
    "    cur_score = 0.0\n",
    "    for tok, sc in zip(tokens, scores):\n",
    "        if drop_special and tok in special_set:\n",
    "            if cur_word:\n",
    "                words.append(cur_word)\n",
    "                word_scores.append(cur_score)\n",
    "                cur_word, cur_score = \"\", 0.0\n",
    "            continue\n",
    "        if tok.startswith(\"Ä \"):\n",
    "            if cur_word:\n",
    "                words.append(cur_word)\n",
    "                word_scores.append(cur_score)\n",
    "            cur_word = tok[1:]\n",
    "            cur_score = float(sc)\n",
    "        else:\n",
    "            cur_word += tok\n",
    "            cur_score += float(sc)\n",
    "    if cur_word:\n",
    "        words.append(cur_word)\n",
    "        word_scores.append(cur_score)\n",
    "    return words, np.array(word_scores, dtype=float)\n",
    "\n",
    "def normalize_scores(scores: np.ndarray):\n",
    "    if scores.size == 0:\n",
    "        return scores\n",
    "    s = scores - scores.mean()\n",
    "    denom = np.abs(s).sum()\n",
    "    return s / denom if denom > 0 else s\n",
    "\n",
    "def save_html_heatmap(words, scores, out_path: Path):\n",
    "    max_abs = float(np.max(np.abs(scores))) if np.max(np.abs(scores)) > 0 else 1.0\n",
    "    spans = []\n",
    "    for w, sc in zip(words, scores):\n",
    "        alpha = abs(sc) / max_abs\n",
    "        color = f\"rgba(255,0,0,{alpha})\" if sc >= 0 else f\"rgba(0,0,255,{alpha})\"\n",
    "        spans.append(f\"<span style='background-color:{color}; padding:2px; margin:1px; border-radius:3px'>{w}</span>\")\n",
    "    html = f\"<html><body><div style='line-height:2.0'>{' '.join(spans)}</div></body></html>\"\n",
    "    out_path.write_text(html, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Integrated Gradients\n",
    "# =========================\n",
    "\n",
    "def explain_one_text(tokenizer, model, text: str, target_id: int, n_steps: int = N_STEPS_IG):\n",
    "    enc = encode_one(tokenizer, text)\n",
    "    input_ids = enc[\"input_ids\"]\n",
    "    attn = enc[\"attention_mask\"]\n",
    "    baseline = build_baseline_like(tokenizer, input_ids)\n",
    "\n",
    "    lig = LayerIntegratedGradients(lambda ids, mask: forward_fn(model, ids, mask), model.roberta.embeddings)\n",
    "    attributions, delta = lig.attribute(\n",
    "        inputs=input_ids,\n",
    "        baselines=baseline,\n",
    "        additional_forward_args=(attn,),\n",
    "        target=target_id,\n",
    "        n_steps=n_steps,\n",
    "        return_convergence_delta=True,\n",
    "    )\n",
    "\n",
    "    token_attr = attributions.sum(dim=-1).squeeze(0).detach().cpu().numpy()\n",
    "    tokens = tokens_from_ids(tokenizer, input_ids.squeeze(0))\n",
    "    words, word_scores = merge_roberta_pieces(tokenizer, tokens, token_attr, drop_special=True)\n",
    "    word_scores = normalize_scores(word_scores)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probs = torch.softmax(forward_fn(model, input_ids, attn), dim=-1).squeeze(0).cpu().numpy()\n",
    "    return words, word_scores, float(probs[target_id]), float(delta.squeeze().detach().cpu().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "689202dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Single sample explain\n",
    "# =========================\n",
    "\n",
    "def explain_single_samples(sample_texts, suicide_id: int, out_dir: Path, tokenizer, model, top_k: int = 12):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for i, t in enumerate(sample_texts, start=1):\n",
    "        words, scores, p_su, delta = explain_one_text(tokenizer, model, t, suicide_id, N_STEPS_IG)\n",
    "        # print top toward and away\n",
    "        arr = np.array(scores)\n",
    "        idx = np.argsort(arr)\n",
    "        neg_idx = idx[:top_k]\n",
    "        pos_idx = idx[-top_k:][::-1]\n",
    "        print(f\"\\nSample {i}  suicide prob={p_su:.3f}\")\n",
    "        print(\"\\nTop words that push toward suicidal\")\n",
    "        for j in pos_idx:\n",
    "            print(f\"{words[j]:20s}  {arr[j]: .4f}\")\n",
    "        print(\"\\nTop words that push away from suicidal\")\n",
    "        for j in neg_idx:\n",
    "            print(f\"{words[j]:20s}  {arr[j]: .4f}\")\n",
    "\n",
    "        save_html_heatmap(words, arr, out_dir / f\"ig_single_{i}.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30c78fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Batch predict and sets\n",
    "# =========================\n",
    "\n",
    "def predict_batch(texts, tokenizer, model, batch_size=4):\n",
    "    preds, probs = [], []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(\n",
    "            batch,\n",
    "            truncation=True,\n",
    "            max_length=MAX_LEN,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "        ).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            logits = model(**enc).logits\n",
    "            p = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "            y = p.argmax(axis=1)\n",
    "        preds.extend(y.tolist())\n",
    "        probs.extend(p.tolist())\n",
    "    \n",
    "        del enc, logits\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    return np.array(preds), np.array(probs)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Batch explain and aggregate\n",
    "# =========================\n",
    "\n",
    "def sample_indices(arr, k, seed=RANDOM_STATE):\n",
    "    lst = list(arr)\n",
    "    random.Random(seed).shuffle(lst)\n",
    "    return lst[:min(len(lst), k)]\n",
    "\n",
    "def aggregate_for_indices(name, indices, texts, suicide_id, tokenizer, model, out_dir: Path, top_save=50):\n",
    "    agg_toward = Counter()\n",
    "    agg_away = Counter()\n",
    "    meta = []\n",
    "\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for j, idx in enumerate(indices, start=1):\n",
    "        text = texts[idx]\n",
    "        words, scores, p_su, delta = explain_one_text(tokenizer, model, text, suicide_id, N_STEPS_IG)\n",
    "\n",
    "        save_html_heatmap(words, scores, out_dir / f\"ig_{name}_{j}.html\")\n",
    "\n",
    "        for w, sc in zip(words, scores):\n",
    "            if not w or not w.strip():\n",
    "                continue\n",
    "            if sc >= 0:\n",
    "                agg_toward[w] += float(sc)\n",
    "            else:\n",
    "                agg_away[w] += float(-sc)\n",
    "\n",
    "        meta.append({\n",
    "            \"idx\": int(idx),\n",
    "            \"suicide_prob\": p_su,\n",
    "            \"text\": text[:5000]\n",
    "        })\n",
    "\n",
    "    df_toward = pd.DataFrame(agg_toward.items(), columns=[\"word\", \"score\"]).sort_values(\"score\", ascending=False)\n",
    "    df_away = pd.DataFrame(agg_away.items(), columns=[\"word\", \"score\"]).sort_values(\"score\", ascending=False)\n",
    "    df_meta = pd.DataFrame(meta)\n",
    "\n",
    "    df_toward.head(top_save).to_csv(out_dir / f\"agg_{name}_top_toward.csv\", index=False)\n",
    "    df_away.head(top_save).to_csv(out_dir / f\"agg_{name}_top_away.csv\", index=False)\n",
    "    df_meta.to_csv(out_dir / f\"samples_{name}.csv\", index=False)\n",
    "\n",
    "    print(f\"[{name}] saved CSVs and HTML\")\n",
    "    return df_toward, df_away\n",
    "\n",
    "\n",
    "def batch_explain(df_test, class_to_id, tokenizer, model, out_dir: Path, max_explains=100):\n",
    "    texts = df_test[\"text\"].astype(str).tolist()\n",
    "    y_true = df_test[\"label\"].astype(str).str.lower().map(class_to_id).to_numpy()\n",
    "\n",
    "    y_pred, y_prob = predict_batch(texts, tokenizer, model, batch_size=4)\n",
    "\n",
    "    idx_dep = class_to_id[\"depression\"]\n",
    "    idx_su = class_to_id[\"suicide\"]\n",
    "\n",
    "    fp_dep_to_su = np.where((y_true == idx_dep) & (y_pred == idx_su))[0]\n",
    "    fn_su_to_other = np.where((y_true == idx_su) & (y_pred != idx_su))[0]\n",
    "    tp_su = np.where((y_true == idx_su) & (y_pred == idx_su))[0]\n",
    "\n",
    "    fp_s = sample_indices(fp_dep_to_su, max_explains)\n",
    "    fn_s = sample_indices(fn_su_to_other, max_explains)\n",
    "    tp_s = sample_indices(tp_su, max_explains)\n",
    "\n",
    "    print(f\"Selected counts  FP_dep_to_su={len(fp_s)}  FN_su_to_other={len(fn_s)}  TP_su={len(tp_s)}\")\n",
    "\n",
    "    toward_fp, away_fp = aggregate_for_indices(\"fp_dep_to_suicide\", fp_s, texts, idx_su, tokenizer, model, out_dir)\n",
    "    toward_fn, away_fn = aggregate_for_indices(\"fn_suicide_to_other\", fn_s, texts, idx_su, tokenizer, model, out_dir)\n",
    "    toward_tp, away_tp = aggregate_for_indices(\"tp_suicide\", tp_s, texts, idx_su, tokenizer, model, out_dir)\n",
    "\n",
    "    # optional overlap report between TP toward and FP toward\n",
    "    overlap = set(toward_tp.head(100)[\"word\"]).intersection(set(toward_fp.head(100)[\"word\"]))\n",
    "    pd.Series(sorted(overlap)).to_csv(out_dir / \"overlap_tp_vs_fp_toward_words.csv\", index=False)\n",
    "    print(\"Saved overlap list of top drivers between TP and FP\")\n",
    "\n",
    "    return {\n",
    "        \"fp_counts\": len(fp_s),\n",
    "        \"fn_counts\": len(fn_s),\n",
    "        \"tp_counts\": len(tp_s),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99c9b9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Data Warehouse: d:\\Sajjad-Workspace\\PSS_XAI\\Data_Process\\Data_Warehouse\n",
      "Using split dir: d:\\Sajjad-Workspace\\PSS_XAI\\Data_Process\\Data_Warehouse\\mental_health_splits_no_stress\n",
      "Using model dir: d:\\Sajjad-Workspace\\PSS_XAI\\Data_Process\\Data_Warehouse\\mental_health_splits_no_stress\\all_roberta_large_v1_multiclass\\best\n",
      "Selected counts  FP_dep_to_su=23  FN_su_to_other=14  TP_su=70\n",
      "[fp_dep_to_suicide] saved CSVs and HTML\n",
      "[fn_suicide_to_other] saved CSVs and HTML\n",
      "[tp_suicide] saved CSVs and HTML\n",
      "Saved overlap list of top drivers between TP and FP\n",
      "Batch stats: {'fp_counts': 23, 'fn_counts': 14, 'tp_counts': 70}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Main entry\n",
    "# =========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Using Data Warehouse:\", DATA_WAREHOUSE)\n",
    "    print(\"Using split dir:\", SPLIT_DIR)\n",
    "    print(\"Using model dir:\", MODEL_DIR)\n",
    "\n",
    "    df_test, class_to_id, id_to_class = load_test_and_mapping()\n",
    "    tokenizer, model = load_model_and_tokenizer()\n",
    "    suicide_id = class_to_id[\"suicide\"]\n",
    "\n",
    "    # ===== single mode example =====\n",
    "    # Option A: pick texts from test\n",
    "    texts_for_single = []\n",
    "    df_su = df_test[df_test[\"label\"].astype(str).str.lower() == \"suicide\"]\n",
    "    if not df_su.empty:\n",
    "        texts_for_single.append(df_su.sample(1, random_state=17)[\"text\"].iloc[0])\n",
    "    df_dep = df_test[df_test[\"label\"].astype(str).str.lower() == \"depression\"]\n",
    "    if not df_dep.empty:\n",
    "        texts_for_single.append(df_dep.sample(1, random_state=23)[\"text\"].iloc[0])\n",
    "    # Option B: add your own manual text\n",
    "    if len(texts_for_single) == 0:\n",
    "        texts_for_single.append(\"I am tired of life and I want to end everything\")\n",
    "\n",
    "    RUN_SINGLE = False\n",
    "    RUN_BATCH = True\n",
    "    \n",
    "    if RUN_SINGLE:\n",
    "        single_out_dir = OUTPUT_DIR / \"explain_single\"\n",
    "        explain_single_samples(\n",
    "            sample_texts=texts_for_single,\n",
    "            suicide_id=suicide_id,\n",
    "            out_dir=single_out_dir,\n",
    "            tokenizer=tokenizer,\n",
    "            model=model,\n",
    "            top_k=12,\n",
    "        )\n",
    "\n",
    "    if RUN_BATCH:\n",
    "        batch_out_dir = OUTPUT_DIR / \"explain_batch\"\n",
    "        stats = batch_explain(\n",
    "            df_test=df_test,\n",
    "            class_to_id=class_to_id,\n",
    "            tokenizer=tokenizer,\n",
    "            model=model,\n",
    "            out_dir=batch_out_dir,\n",
    "            max_explains=100,\n",
    "        )\n",
    "        print(\"Batch stats:\", stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d463f1b8",
   "metadata": {},
   "source": [
    "ðŸ”¹ 1. Organize by error type\n",
    "\n",
    "False Negatives (suicide â†’ other)\n",
    "\n",
    "Toward: weak suicide cues (e.g., cutting, dead, insane) appear, but not strong enough for the model.\n",
    "\n",
    "Away: background/benign terms (e.g., school, grades, stuttering, better) suppressed the suicide prediction.\n",
    "\n",
    "Interpretation: the model often misses suicide texts when they are diluted with daily-life or school-related language.\n",
    "\n",
    "False Positives (depression â†’ suicide)\n",
    "\n",
    "Toward: depression posts mentioning suicidal, suicide, hotline, killing push them incorrectly into suicide class.\n",
    "\n",
    "Away: words like manipulative, yourself, excited, phases dampen the suicide score but not enough.\n",
    "\n",
    "Interpretation: the model confuses strong expressions of depression with suicide intent due to lexical overlap.\n",
    "\n",
    "True Positives (suicide â†’ suicide)\n",
    "\n",
    "Toward: explicit suicide intent markers (myself, dying, suicide, kill, death, anymore, want, life) strongly drive correct classification.\n",
    "\n",
    "Away: some neutral context words (deadly, real, problems, family, account) pull slightly away but donâ€™t overturn the prediction.\n",
    "\n",
    "Interpretation: the model is reliable when posts contain direct, explicit suicide markers.\n",
    "\n",
    "ðŸ”¹ 2. Higher-level themes\n",
    "\n",
    "Overlap problem: depression and suicide share vocabulary (life, feelings, help, donâ€™t, canâ€™t), which drives false positives.\n",
    "\n",
    "Dilution problem: everyday or contextual words (school, grades, family) reduce the suicide probability in true suicide posts, driving false negatives.\n",
    "\n",
    "Strong signals: explicit intent markers (suicide, kill, death, myself, dying) consistently separate true suicide posts.\n",
    "\n",
    "ðŸ”¹ 3. Suggested summary paragraph\n",
    "\n",
    "Explainability analysis using Integrated Gradients revealed that true suicide predictions are driven by explicit intent markers such as myself, suicide, kill, death, and dying. False positives (depression misclassified as suicide) occur when depressive texts contain similar lexicon (e.g., suicidal, hotline, killing), highlighting the lexical overlap between depression and suicide. False negatives (suicide misclassified as other) are often associated with everyday context terms (e.g., school, grades, family), which dilute the suicidal signal. These results indicate that the model captures explicit markers well but struggles in borderline cases where suicide intent is implied rather than stated directly, or where depression shares overlapping vocabulary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312_gpu_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
